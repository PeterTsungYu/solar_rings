{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "import cv2\n",
    "import geopandas as gp\n",
    "import descartes\n",
    "from shapely.geometry import Polygon\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from SolCrawler import solpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting descartes\n",
      "  Using cached https://files.pythonhosted.org/packages/e5/b6/1ed2eb03989ae574584664985367ba70cd9cf8b32ee8cad0e8aaeac819f3/descartes-1.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from descartes) (3.1.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->descartes) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->descartes) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /opt/conda/lib/python3.7/site-packages (from matplotlib->descartes) (1.16.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->descartes) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->descartes) (2.4.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->descartes) (1.13.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->descartes) (42.0.0.post20191124)\n",
      "Installing collected packages: descartes\n",
      "Successfully installed descartes-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install descartes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load grid data and weather station data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load grid data\n",
    "taiwan_grid = gp.read_file(\"./MapData/taiwan_grid.shp\")\n",
    "taiwan_offgrid = gp.read_file(\"./MapData/taiwan_offgrid.shp\")\n",
    "\n",
    "assert taiwan_grid.crs == 'epsg:3824' \n",
    "assert taiwan_offgrid.crs == 'epsg:3824' \n",
    "\n",
    "\n",
    "# get centroids of each grid\n",
    "# make centrod as each grid's 'longitude' 'latitude'\n",
    "centroid = taiwan_grid['geometry'].centroid\n",
    "taiwan_grid['longitude'] = centroid.x\n",
    "taiwan_grid['latitude'] = centroid.y\n",
    "#taiwan_grid\n",
    "\n",
    "\n",
    "# load the weather station info including 'longitude' 'latitude'\n",
    "Sta_df = pd.read_csv('WeatherStation.csv')\n",
    "# make Geodataframe (geometry points) out of the 'longitude' 'latitude'\n",
    "## to locate all the stations in the grid\n",
    "Sta_gdf = gp.GeoDataFrame(\n",
    "    Sta_df, geometry=gp.points_from_xy(Sta_df.Longitude, Sta_df.Latitude), crs=taiwan_grid.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load fill_CODiS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'taiwan_grid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-80214666bece>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# for split the alltime into time-by-time dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m## split by the total number of grids (66)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtaiwan_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'taiwan_grid' is not defined"
     ]
    }
   ],
   "source": [
    "# loop over the fill_CODiS folder\n",
    "fill_csv = sorted(glob.glob('fill_CODiS/*.csv'))\n",
    "#print(fill_csv)\n",
    "\n",
    "\n",
    "# ['StnPres', 'Temperature'] min and max\n",
    "## to get the original 'StnPres', 'Temperature' for the SOLPOS input \n",
    "p_max, t_max = pd.read_csv(\"./scale_max.csv\").iloc[:2, 0]  \n",
    "p_min, t_min = pd.read_csv(\"./scale_min.csv\").iloc[:2, 0]\n",
    "#print(p_max, t_max, p_min, t_min)\n",
    "\n",
    "# for split the alltime into time-by-time dataframe\n",
    "## split by the total number of grids (66)\n",
    "split = taiwan_grid.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## locate each station, and count the number of stations in each cell of the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [[] for i in range(len(taiwan_grid))]\n",
    "for i in tqdm.tqdm_notebook(range(len(Sta_gdf))):\n",
    "    for u in range(len(taiwan_grid)):\n",
    "        # check if the geometry point of station is in the geometry polygon of grid\n",
    "        if Sta_gdf.loc[i, 'geometry'].within(taiwan_grid.loc[u, 'geometry']):\n",
    "            fields[u].append(i)\n",
    "#fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN impute the whole grid, and query for the SOLPOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for searching the digital number in the file name\n",
    "## 2017-01-01_H01\n",
    "p = re.compile(r'\\d+')\n",
    "\n",
    "# loop over the fill_CODiS folder\n",
    "for name in tqdm.tqdm_notebook(fill_csv[475:]):\n",
    "    #print(name)\n",
    "\n",
    "    # load each fill_CODiS time by time\n",
    "    codis = pd.read_csv(name)\n",
    "\n",
    "    # initiate features in the taiwan_grid \n",
    "    for i in ['StnPres', 'Temperature', 'RH', 'WS', 'WD_sin', 'WD_cos', 'Precp', 'AM', 'CosInc', 'Hour', 'ETR']:\n",
    "        taiwan_grid[i] = 0.0\n",
    "    #taiwan_grid\n",
    "\n",
    "    # loop over the count of stations in each cell\n",
    "    for u, i in enumerate(fields):\n",
    "        if len(i)>0:\n",
    "            for j in i:\n",
    "                ## if the cell has stations, then accumulate the values in the fill_CODiS\n",
    "                # 4:11 & 7:14 ['StnPres', 'Temperature', 'RH', 'WS', 'WD_sin', 'WD_cos', 'Precp']\n",
    "                taiwan_grid.iloc[u, 4:11] += codis.iloc[j, 7:14]\n",
    "            # take average value for each cell\n",
    "            taiwan_grid.iloc[u, 4:11] /= len(i)\n",
    "        else:\n",
    "            # if the cell has no station located, then set as nan\n",
    "            taiwan_grid.iloc[u, 4:11] =np.nan\n",
    "    \n",
    "    # impute the rest of the cell (the nan) by KNN time by time, make the whole grid filled \n",
    "    ## the KNN takes scaled data (0.0-1.0)\n",
    "    imputer = KNNImputer(n_neighbors=3)#, copy=True)\n",
    "    taiwan_grid[['longitude', 'latitude', 'StnPres', 'Temperature', 'RH', 'WS', 'WD_sin', 'WD_cos', 'Precp']] = \\\n",
    "    imputer.fit_transform(taiwan_grid[['longitude', 'latitude', 'StnPres', 'Temperature', 'RH', 'WS', 'WD_sin', 'WD_cos', 'Precp']])\n",
    "\n",
    "    # reverse the scale to original \"StnPres\", \"Temperature\" for the SOLPOS\n",
    "    taiwan_grid['StnPres_ori'] = taiwan_grid['StnPres']*(p_max-p_min)+p_min\n",
    "    taiwan_grid['Temperature_ori'] = taiwan_grid['Temperature']*(t_max-t_min)+t_min\n",
    "    #print(taiwan_grid)\n",
    "\n",
    "    #query for SOLPOS\n",
    "    date = p.findall(name) # digital number in the file name\n",
    "    #print(date)\n",
    "\n",
    "    # per day\n",
    "    syear, smonth, sday, hour = date\n",
    "    eyear, emonth, eday = syear, smonth, sday\n",
    "    # for a certain time (hour) in a day\n",
    "    hour = int(hour)\n",
    "\n",
    "    # the query is each cell's 'latitude', 'longitude', 'StnPres_ori', 'Temperature_ori'\n",
    "    ## hence, the whole grid could be filled\n",
    "    for i in range(len(taiwan_grid)):\n",
    "        StaLoc = dict(taiwan_grid.loc[i, ['latitude', 'longitude', 'StnPres_ori', 'Temperature_ori']])\n",
    "        #print(StaLoc)\n",
    "        \n",
    "        # call the custom function\n",
    "        am, cosinc, etr = solpos(syear=syear,\n",
    "                         smonth=smonth,\n",
    "                         sday=sday,\n",
    "                         eyear=eyear,\n",
    "                         emonth=emonth,\n",
    "                         eday=eday,\n",
    "                         hour=hour,\n",
    "                         **StaLoc)\n",
    "\n",
    "        # initiate hour as 1.0, meaning sunlight is on\n",
    "        ## this is the sunshine hour in the space\n",
    "        hr = 1.0\n",
    "\n",
    "        # if the sunlight is off, then no AirMass, no incidence, and no sunshine hour\n",
    "        if etr == 0.0:\n",
    "            am, cosinc, hr = 0.0, 0.0, 0.0\n",
    "\n",
    "        # fill the grid time by time (hour by hour)\n",
    "        taiwan_grid.loc[i, ['AM', 'CosInc', 'Hour', 'ETR']] = (am, cosinc, hr, etr)\n",
    "        #print(am, cosinc, hr, etr)\n",
    "        \n",
    "    # save as temporary archive hour by hour\n",
    "    taiwan_grid.iloc[:, 2:].to_csv('grid_'+name, index=False)\n",
    "\n",
    "#     alltime_grid = pd.concat((alltime_grid, taiwan_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concate the grid for the all-time grid to scale 'AM' 'CosInc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concate the temporary archive\n",
    "## for future use, no need for the \"pd.read_csv('alltime_grid.csv')\"\n",
    "alltime_grid = pd.DataFrame(columns = cols)\n",
    "#alltime_grid = pd.read_csv('alltime_grid.csv')\n",
    "grid_csv = sorted(glob.glob('grid_fill_CODiS/grid_Station_bytime_2017/*.csv'))\n",
    "for i in grid_csv:\n",
    "    grid_tmp = pd.read_csv(i)\n",
    "    alltime_grid = pd.concat((alltime_grid, grid_tmp))\n",
    "# for future use, no ignore_index \"alltime_grid = pd.concat((alltime_grid, grid_tmp))\"\n",
    "## cuz it is usefule for the later maych-up between two dataframe with same index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['AM', 'CosInc'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5257bfac6d77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# -4: [AM, CosInc, ETR]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m## except 'Hour', it is defined in the function as 0.0/1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0malltime_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'AM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CosInc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msol_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malltime_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'AM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CosInc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#assert alltime_grid.crs == 'epsg:3824'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1416\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    820\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1837\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m             \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m             return self.obj._reindex_with_indexers(\n\u001b[1;32m   1135\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1092\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m         )\n\u001b[1;32m   1094\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 raise KeyError(\n\u001b[1;32m   1176\u001b[0m                     \"None of [{key}] are in the [{axis}]\".format(\n\u001b[0;32m-> 1177\u001b[0;31m                         \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m                     )\n\u001b[1;32m   1179\u001b[0m                 )\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['AM', 'CosInc'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# reset the index  470/744 [7:19:09<4:35:44, 57.45s/it]\n",
    "## should comment it for future use\n",
    "alltime_grid.index = range(len(alltime_grid))\n",
    "\n",
    "\n",
    "# scale the 'AM' 'CosInc' across all time\n",
    "sol_scaler = MinMaxScaler((0, 1), copy=True)\n",
    "# -4: [AM, CosInc, ETR]\n",
    "## except 'Hour', it is defined in the function as 0.0/1.0\n",
    "alltime_grid.loc[:, ['AM', 'CosInc']] = sol_scaler.fit_transform(alltime_grid.loc[:, ['AM', 'CosInc']])\n",
    "\n",
    "#assert alltime_grid.crs == 'epsg:3824'\n",
    "\n",
    "alltime_grid.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Stations', 'Altitude', 'Latitude', 'Longitude', 'altitude_s',\n",
       "       'latitude_s', 'longitude_s', 'StnPres', 'Temperature', 'RH', 'WS',\n",
       "       'WD_sin', 'WD_cos', 'Precp', 'SunShine', 'GloblRad'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = pd.read_csv('./fill_CODiS/fill2_Station_bytime_2017/2017-01-20_H23.csv').columns\n",
    "cols     #et091-group6/fill_CODiS/fill2_Station_bytime_2017/2017-01-01_H08.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltime_grid = pd.DataFrame(columns = cols)\n",
    "#alltime_grid = pd.read_csv('alltime_grid.csv')\n",
    "grid_csv = sorted(glob.glob('fill_CODiS/fill2_Station_bytime_2017/*.csv'))\n",
    "for i in grid_csv:\n",
    "    grid_tmp = pd.read_csv(i)\n",
    "    alltime_grid = pd.concat((alltime_grid, grid_tmp[:9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Altitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>altitude_s</th>\n",
       "      <th>latitude_s</th>\n",
       "      <th>longitude_s</th>\n",
       "      <th>StnPres</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RH</th>\n",
       "      <th>WS</th>\n",
       "      <th>WD_sin</th>\n",
       "      <th>WD_cos</th>\n",
       "      <th>Precp</th>\n",
       "      <th>SunShine</th>\n",
       "      <th>GloblRad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>78840.000000</td>\n",
       "      <td>78840.000000</td>\n",
       "      <td>78840.000000</td>\n",
       "      <td>78840.000000</td>\n",
       "      <td>78840.000000</td>\n",
       "      <td>78840.000000</td>\n",
       "      <td>78840.000000</td>\n",
       "      <td>78840.000000</td>\n",
       "      <td>78840.000000</td>\n",
       "      <td>78840.000000</td>\n",
       "      <td>78840.000000</td>\n",
       "      <td>78840.000000</td>\n",
       "      <td>78840.000000</td>\n",
       "      <td>78840.000000</td>\n",
       "      <td>78840.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>284.933333</td>\n",
       "      <td>22.867889</td>\n",
       "      <td>120.686822</td>\n",
       "      <td>0.117332</td>\n",
       "      <td>0.567774</td>\n",
       "      <td>0.452985</td>\n",
       "      <td>0.948007</td>\n",
       "      <td>0.610812</td>\n",
       "      <td>0.753698</td>\n",
       "      <td>0.131543</td>\n",
       "      <td>0.501320</td>\n",
       "      <td>0.718085</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.231342</td>\n",
       "      <td>0.615728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>752.632896</td>\n",
       "      <td>0.473199</td>\n",
       "      <td>0.393556</td>\n",
       "      <td>0.312114</td>\n",
       "      <td>0.277813</td>\n",
       "      <td>0.296866</td>\n",
       "      <td>0.074641</td>\n",
       "      <td>0.143222</td>\n",
       "      <td>0.112032</td>\n",
       "      <td>0.093615</td>\n",
       "      <td>0.302842</td>\n",
       "      <td>0.332178</td>\n",
       "      <td>0.010509</td>\n",
       "      <td>0.382110</td>\n",
       "      <td>0.943352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.300000</td>\n",
       "      <td>22.003900</td>\n",
       "      <td>120.204800</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.060530</td>\n",
       "      <td>0.089387</td>\n",
       "      <td>0.723449</td>\n",
       "      <td>0.030374</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.100000</td>\n",
       "      <td>22.566000</td>\n",
       "      <td>120.315700</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>0.390536</td>\n",
       "      <td>0.173041</td>\n",
       "      <td>0.969133</td>\n",
       "      <td>0.521028</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.059783</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22.300000</td>\n",
       "      <td>22.993200</td>\n",
       "      <td>120.746300</td>\n",
       "      <td>0.008418</td>\n",
       "      <td>0.641343</td>\n",
       "      <td>0.497850</td>\n",
       "      <td>0.973088</td>\n",
       "      <td>0.640187</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.883022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>33.500000</td>\n",
       "      <td>23.097500</td>\n",
       "      <td>120.903800</td>\n",
       "      <td>0.013063</td>\n",
       "      <td>0.702577</td>\n",
       "      <td>0.616655</td>\n",
       "      <td>0.977428</td>\n",
       "      <td>0.717290</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.179348</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.969846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2413.400000</td>\n",
       "      <td>23.508200</td>\n",
       "      <td>121.373400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943698</td>\n",
       "      <td>0.970883</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.932243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.410468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.360000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Altitude      Latitude     Longitude    altitude_s    latitude_s  \\\n",
       "count  78840.000000  78840.000000  78840.000000  78840.000000  78840.000000   \n",
       "mean     284.933333     22.867889    120.686822      0.117332      0.567774   \n",
       "std      752.632896      0.473199      0.393556      0.312114      0.277813   \n",
       "min        2.300000     22.003900    120.204800      0.000124      0.060530   \n",
       "25%        8.100000     22.566000    120.315700      0.002530      0.390536   \n",
       "50%       22.300000     22.993200    120.746300      0.008418      0.641343   \n",
       "75%       33.500000     23.097500    120.903800      0.013063      0.702577   \n",
       "max     2413.400000     23.508200    121.373400      1.000000      0.943698   \n",
       "\n",
       "        longitude_s       StnPres   Temperature            RH            WS  \\\n",
       "count  78840.000000  78840.000000  78840.000000  78840.000000  78840.000000   \n",
       "mean       0.452985      0.948007      0.610812      0.753698      0.131543   \n",
       "std        0.296866      0.074641      0.143222      0.112032      0.093615   \n",
       "min        0.089387      0.723449      0.030374      0.130000      0.000000   \n",
       "25%        0.173041      0.969133      0.521028      0.680000      0.059783   \n",
       "50%        0.497850      0.973088      0.640187      0.750000      0.108696   \n",
       "75%        0.616655      0.977428      0.717290      0.830000      0.179348   \n",
       "max        0.970883      1.000000      0.932243      1.000000      0.804348   \n",
       "\n",
       "             WD_sin        WD_cos         Precp      SunShine      GloblRad  \n",
       "count  78840.000000  78840.000000  78840.000000  78840.000000  78840.000000  \n",
       "mean       0.501320      0.718085      0.001301      0.231342      0.615728  \n",
       "std        0.302842      0.332178      0.010509      0.382110      0.943352  \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000  \n",
       "25%        0.250000      0.500000      0.000000      0.000000      0.000000  \n",
       "50%        0.500000      0.883022      0.000000      0.000000      0.000000  \n",
       "75%        0.750000      0.969846      0.000000      0.400000      1.030000  \n",
       "max        1.000000      1.000000      0.410468      1.000000      4.360000  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alltime_grid.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(alltime_grid.isna()['GloblRad'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop the some useless features, keep the useful features for generating featmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltime_grid = alltime_grid.drop(['longitude', 'latitude', 'StnPres', 'Temperature', 'StnPres_ori', 'Temperature_ori'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate featmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-84ad31668280>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# initiate the taiwan_grid and taiwan_offgrid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtaiwan_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./MapData/taiwan_grid.shp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtaiwan_offgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./MapData/taiwan_offgrid.shp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'RH'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'WS'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'WD_sin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'WD_cos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Precp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CosInc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Hour'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ETR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gp' is not defined"
     ]
    }
   ],
   "source": [
    "# initiate the taiwan_grid and taiwan_offgrid\n",
    "taiwan_grid = gp.read_file(\"./MapData/taiwan_grid.shp\")\n",
    "taiwan_offgrid = gp.read_file(\"./MapData/taiwan_offgrid.shp\")\n",
    "\n",
    "for i in ['RH', 'WS', 'WD_sin', 'WD_cos', 'Precp', 'AM', 'CosInc', 'Hour', 'ETR']:\n",
    "    taiwan_grid[i] = 0.0\n",
    "    taiwan_offgrid[i] = 0.0 # taiwan_offgrid values will be always 0.0\n",
    "\n",
    "# params for the image plot\n",
    "## trial&error for the pixel values\n",
    "### to match the 200x155 image size\n",
    "dpi = 100\n",
    "width_pixel = 200\n",
    "height_pixel = 350\n",
    "\n",
    "# the scope is bounds of taiwan_offgrid \n",
    "left_bound = taiwan_offgrid.total_bounds[0]\n",
    "right_bound = taiwan_offgrid.total_bounds[2]\n",
    "bottom_bound = taiwan_offgrid.total_bounds[1]\n",
    "top_bound = taiwan_offgrid.total_bounds[3]\n",
    "\n",
    "# params for slicing the image array (clip the image)\n",
    "left = 25\n",
    "right = 179\n",
    "top = 74\n",
    "bottom = 273\n",
    "\n",
    "# loop over the fill_CODiS hour by hour\n",
    "for i in tqdm.tqdm_notebook(range(len(fill_csv))):\n",
    "#for i in tqdm.tqdm_notebook(range(3)):\n",
    "    \n",
    "    # 2017-01-01_H01\n",
    "    npy_name = re.search(r'\\d{4}-\\d{2}-\\d{2}_H\\d{2}', fill_csv[i]).group()\n",
    "    \n",
    "    # split the all-time grid into each time slot (per hour)\n",
    "    ## match two dataframe by the same index range\n",
    "    taiwan_grid.loc[:, ['RH', 'WS', 'WD_sin', 'WD_cos', 'Precp', 'AM', 'CosInc', 'Hour', 'ETR']] = \\\n",
    "    alltime_grid.loc[(i*split):((i+1)*split-1), ['RH', 'WS', 'WD_sin', 'WD_cos', 'Precp', 'AM', 'CosInc', 'Hour', 'ETR']].reset_index(drop=True)\n",
    "    \n",
    "    # concate taiwan_grid with taiwan_offgrid to plot a whole grid\n",
    "    featmap = pd.concat([taiwan_grid, taiwan_offgrid], ignore_index=True)\n",
    "    #print(featmap)\n",
    "    \n",
    "        # generate featmaps by using plt.plot to acquire image array\n",
    "        ## the plt.plot will scale the range from 0.0-1.0 up to 0-255\n",
    "    for feat in ['RH', 'WS', 'WD_sin', 'WD_cos', 'Precp', 'AM', 'CosInc']:\n",
    "    \n",
    "        # set the figsize by inches\n",
    "        fig, ax = plt.subplots(figsize=(width_pixel/dpi, height_pixel/dpi), dpi=dpi)\n",
    "        # acquire the the canvas for the figure\n",
    "        canvas = FigureCanvasAgg(fig)\n",
    "        \n",
    "        # add the max range to make sure the scaled scope of each img (time after time) is same\n",
    "        ## since all the value is scaled between 0.0 to 1.0, then the max is 1.0\n",
    "        featmap.plot(ax=ax, column=feat, cmap='gray', vmax=1.0)\n",
    "        #print(featmap)\n",
    "\n",
    "        ax.set_axis_off()\n",
    "        ax.set_xlim(left=left_bound, right=right_bound)\n",
    "        ax.set_ylim(bottom=bottom_bound, top=top_bound)\n",
    "\n",
    "        # Retrieve a view on the renderer buffer\n",
    "        canvas.draw()\n",
    "        buf = canvas.buffer_rgba()\n",
    "        X = np.asarray(buf)\n",
    "\n",
    "# comment after knowing the values\n",
    "#         assert sum(sum(X[:,:,0] != X[:,:,1])) == 0\n",
    "#         assert sum(sum(X[:,:,2] != X[:,:,1])) == 0\n",
    "        \n",
    "        # make sure the three channels are equal\n",
    "        ## output should be one channel for each feature\n",
    "        X = X[:,:,0]\n",
    "\n",
    "# comment after knowing the values\n",
    "#         width_mean = X.mean(axis=0)\n",
    "#         height_mean = X.mean(axis=1)\n",
    "#         width_ind = np.arange(X.shape[-1])\n",
    "#         height_ind = np.arange(X.shape[0])\n",
    "#         left = width_ind[list(width_mean != 255.0)][0]\n",
    "#         right = width_ind[list(width_mean != 255.0)][-1]\n",
    "#         top = height_ind[list(height_mean != 255.0)][0]\n",
    "#         bottom = height_ind[list(height_mean != 255.0)][-1]\n",
    "#         print(left, right, top, bottom)\n",
    "\n",
    "        img = X[top:bottom+1, left:right+1]\n",
    "        #print(img)\n",
    "        \n",
    "        # add the max range to make sure the scale scope of each img\n",
    "#         img[scale_mask] = 0.0\n",
    "        #print(img)\n",
    "        \n",
    "        # save as numpy array\n",
    "        np.save(f'./FeatMap/{feat}/{npy_name}.npy', img)\n",
    "        #cv2.imwrite(f'./FeatMap/{feat}/{img_name}.png', img)\n",
    "        #plt.imshow(img)\n",
    "        plt.close()\n",
    "        \n",
    "        \n",
    "        # generate featmaps by filling the original values into corresponding array\n",
    "        ## applying the boolean mask for each cell \n",
    "        for feat in ['Hour', 'ETR']:\n",
    "            predmap = np.zeros((200, 155), dtype='float32')\n",
    "        \n",
    "            for grid in range(split):\n",
    "                #print(sta,grid)\n",
    "                predmap[np.load(f'./Grid_BoolMask/grid_{grid}.npy')] = featmap.loc[grid, feat]\n",
    "            \n",
    "            # save as numpy array    \n",
    "            np.save(f'./FeatMap/{feat}/{npy_name}.npy', predmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in ['RH', 'WS', 'WD_sin', 'WD_cos', 'Precp', 'AM', 'CosInc', 'Hour', 'ETR']:\n",
    "    assert len(os.listdir(f\"./FeatMap/{feat}\")) == (len(fill_csv) +1) # 1 for .ipynb checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
